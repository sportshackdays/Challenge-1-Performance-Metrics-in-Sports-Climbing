{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import cv2\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_bounding_box_from_keypoints(row):\n",
    "    \"\"\"\n",
    "    This function takes a row of a DataFrame where keypoints are stored as 'keypoint_x' and 'keypoint_y' pairs,\n",
    "    finds the minimum and maximum coordinates, and returns the bounding box as (x, y, w, h).\n",
    "\n",
    "    Parameters:\n",
    "    row (pandas.Series): A row of a DataFrame containing keypoints for a frame.\n",
    "\n",
    "    Returns:\n",
    "    bbox (tuple): A tuple (x, y, w, h) representing the bounding box.\n",
    "    \"\"\"\n",
    "    # Filter out all keypoint_x and keypoint_y columns from the row\n",
    "    keypoint_x_cols = [col for col in row.index if '_x' in col]\n",
    "    keypoint_y_cols = [col for col in row.index if '_y' in col]\n",
    "\n",
    "    # Extract the x and y coordinates as lists\n",
    "    keypoint_x_values = row[keypoint_x_cols].values\n",
    "    keypoint_y_values = row[keypoint_y_cols].values\n",
    "\n",
    "    # Find the minimum and maximum values of x and y\n",
    "    min_x, max_x = min(keypoint_x_values), max(keypoint_x_values)\n",
    "    min_y, max_y = min(keypoint_y_values), max(keypoint_y_values)\n",
    "\n",
    "    # Calculate the width and height of the bounding box\n",
    "    width = max_x - min_x + 20\n",
    "    height = max_y - min_y + 20\n",
    "\n",
    "    # Return the bounding box as (x, y, w, h)\n",
    "    return pd.Series([int(min_x), int(min_y), int(width), int(height)], index=['bbox_x', 'bbox_y', 'bbox_w', 'bbox_h'])\n",
    "\n",
    "\n",
    "def convert_string_to_array(string):\n",
    "    return np.array(ast.literal_eval(string))\n",
    "\n",
    "\n",
    "def is_bbox_overlap(bbox1, bbox2):\n",
    "    x1_min, y1_min, x1_max, y1_max = bbox1[0], bbox1[1], bbox1[0] + bbox1[2], bbox1[1] + bbox1[3]\n",
    "    x2_min, y2_min, x2_max, y2_max = bbox2[0], bbox2[1], bbox2[0] + bbox2[2], bbox2[1] + bbox2[3]\n",
    "\n",
    "    return not (x1_max < x2_min or x1_min > x2_max or y1_max < y2_min or y1_min > y2_max)\n",
    "\n",
    "def remove_duplicates(bboxes):\n",
    "    unique_bboxes = []\n",
    "    seen = set()  # Set to keep track of seen bounding boxes\n",
    "\n",
    "    for bbox in bboxes:\n",
    "        # Create a tuple for the first four elements only\n",
    "        simplified_bbox = tuple(bbox[:4])\n",
    "        if simplified_bbox not in seen:\n",
    "            seen.add(simplified_bbox)  # Add to seen set\n",
    "            unique_bboxes.append(simplified_bbox)  # Add to the unique list\n",
    "\n",
    "    return unique_bboxes\n",
    "\n",
    "def extract_keypoints(df_cam14):\n",
    "    \"\"\"\n",
    "    Extracts keypoints from the 'keypoints' column of the dataframe and creates new columns for each keypoint's x and y coordinates.\n",
    "\n",
    "    Parameters:\n",
    "    df_cam14 (pd.DataFrame): DataFrame containing a 'keypoints' column with keypoint data.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with new columns for each keypoint's x and y coordinates.\n",
    "    \"\"\"\n",
    "    for i in range(17):\n",
    "        df_cam14[f'keypoint_{i+1:02d}_x'] = df_cam14['keypoints'].apply(lambda k: k[i][0])\n",
    "        df_cam14[f'keypoint_{i+1:02d}_y'] = df_cam14['keypoints'].apply(lambda k: k[i][1])\n",
    "    return df_cam14\n",
    "\n",
    "def assign_object_ids(df):\n",
    "    df['object_id'] = 0\n",
    "    for i in range(len(df)):\n",
    "        current_bbox = df.loc[i, ['bbox_keypoint_x', 'bbox_keypoint_y', 'bbox_keypoint_w', 'bbox_keypoint_h']].values\n",
    "        found_overlap = False\n",
    "\n",
    "        # Check the previous 20 rows for overlapping bounding boxes\n",
    "        for j in range(max(0, i - 5), i):\n",
    "            previous_bbox = df.loc[j, ['bbox_keypoint_x', 'bbox_keypoint_y', 'bbox_keypoint_w', 'bbox_keypoint_h']].values\n",
    "            if is_bbox_overlap(current_bbox, previous_bbox):\n",
    "                df.loc[i, 'object_id'] = df.loc[j, 'object_id']\n",
    "                found_overlap = True\n",
    "                break\n",
    "\n",
    "        # If no overlap is found, assign a new object_id\n",
    "        if not found_overlap:\n",
    "            df.loc[i, 'object_id'] = df['object_id'].max() + 1\n",
    "\n",
    "    return df\n",
    "\n",
    "def expand_keypoints(row):\n",
    "    keypoints = row['keypoints_array']\n",
    "\n",
    "    # Check if the shape is (x, 17, 2)\n",
    "    if len(keypoints.shape) == 3 and keypoints.shape[1:] == (17, 2):\n",
    "        # If shape is (1, 17, 2), reshape to (17, 2) and return as a single row\n",
    "        if keypoints.shape[0] == 1:\n",
    "            # Return a single row, keep all other columns\n",
    "            row_copy = row.copy()\n",
    "            row_copy['keypoints_array'] = keypoints[0]  # Flatten to (17, 2)\n",
    "            return pd.DataFrame([row_copy])\n",
    "\n",
    "        # If shape is (x, 17, 2), create x new rows with the same values for other columns\n",
    "        expanded_rows = pd.DataFrame([row] * keypoints.shape[0])  # Replicate the original row\n",
    "        expanded_rows['keypoints_array'] = list(keypoints)  # Replace with split (17, 2) arrays\n",
    "        return expanded_rows\n",
    "    else:\n",
    "        # If the shape is already (17, 2), return the row unchanged as a DataFrame\n",
    "        return pd.DataFrame([row])\n",
    "\n",
    "def visualize_coco_keypoints(image, all_keypoints, point_size=3, line_size=2):\n",
    "    \"\"\"\n",
    "    Visualizes pose estimation using a specified color-coding scheme.\n",
    "\n",
    "    Parameters:\n",
    "    - image: Input image as a NumPy array.\n",
    "    - all_keypoints: A list of arrays, each containing shape (17, 2) for [x, y] for each keypoint.\n",
    "    \"\"\"\n",
    "\n",
    "    # COCO keypoints mapping\n",
    "    KEYPOINTS = {\n",
    "        'nose': 0, 'left_eye': 1, 'right_eye': 2, 'left_ear': 3, 'right_ear': 4,\n",
    "        'left_shoulder': 5, 'right_shoulder': 6, 'left_elbow': 7, 'right_elbow': 8,\n",
    "        'left_wrist': 9, 'right_wrist': 10, 'left_hip': 11, 'right_hip': 12,\n",
    "        'left_knee': 13, 'right_knee': 14, 'left_ankle': 15, 'right_ankle': 16\n",
    "    }\n",
    "\n",
    "    # Define colors\n",
    "    COLORS = {\n",
    "        'face': (255, 150, 0),  # Blue for face keypoints\n",
    "        'left': (0, 165, 255),  # Orange for left side\n",
    "        'right': (0, 255, 0),  # Green for right side\n",
    "        'shoulder_hip': (255, 150, 0)  # Blue for shoulder-hip connections\n",
    "    }\n",
    "\n",
    "    # Define connections for the body parts\n",
    "    CONNECTIONS = [\n",
    "        # Face connections (blue)\n",
    "        (KEYPOINTS['nose'], KEYPOINTS['left_eye']),\n",
    "        (KEYPOINTS['nose'], KEYPOINTS['right_eye']),\n",
    "        (KEYPOINTS['left_eye'], KEYPOINTS['left_ear']),\n",
    "        (KEYPOINTS['right_eye'], KEYPOINTS['right_ear']),\n",
    "        (KEYPOINTS['left_shoulder'], KEYPOINTS['left_ear']),\n",
    "        (KEYPOINTS['right_shoulder'], KEYPOINTS['right_ear']),\n",
    "\n",
    "        # Left side connections (orange)\n",
    "        (KEYPOINTS['left_shoulder'], KEYPOINTS['left_elbow']),\n",
    "        (KEYPOINTS['left_elbow'], KEYPOINTS['left_wrist']),\n",
    "        (KEYPOINTS['left_hip'], KEYPOINTS['left_knee']),\n",
    "        (KEYPOINTS['left_knee'], KEYPOINTS['left_ankle']),\n",
    "\n",
    "        # Right side connections (green)\n",
    "        (KEYPOINTS['right_shoulder'], KEYPOINTS['right_elbow']),\n",
    "        (KEYPOINTS['right_elbow'], KEYPOINTS['right_wrist']),\n",
    "        (KEYPOINTS['right_hip'], KEYPOINTS['right_knee']),\n",
    "        (KEYPOINTS['right_knee'], KEYPOINTS['right_ankle']),\n",
    "\n",
    "        # Shoulder to hip connections (blue)\n",
    "        (KEYPOINTS['left_shoulder'], KEYPOINTS['left_hip']),\n",
    "        (KEYPOINTS['right_shoulder'], KEYPOINTS['right_hip']),\n",
    "        (KEYPOINTS['left_shoulder'], KEYPOINTS['right_shoulder']),\n",
    "        (KEYPOINTS['left_hip'], KEYPOINTS['right_hip'])\n",
    "    ]\n",
    "\n",
    "    for keypoints in all_keypoints:\n",
    "        for start, end in CONNECTIONS:\n",
    "            if (0 <= keypoints[start][0] < image.shape[1] and\n",
    "                    0 <= keypoints[start][1] < image.shape[0] and\n",
    "                    0 <= keypoints[end][0] < image.shape[1] and\n",
    "                    0 <= keypoints[end][1] < image.shape[0]):\n",
    "\n",
    "                # Determine connection color based on the involved keypoints\n",
    "                if start in [0, 1, 2, 3, 4] and end in [0, 1, 2, 3, 4]:  # Face connections\n",
    "                    line_color = COLORS['face']\n",
    "                elif start in [5, 7, 9, 11, 13, 15] and end in [7, 9, 13, 15]:\n",
    "                    line_color = COLORS['left']\n",
    "                elif start in [6, 8, 10, 12, 14, 16] and end in [8, 10, 14, 16]:\n",
    "                    line_color = COLORS['right']\n",
    "                elif (start in [5, 6, 11, 12] and end in [3, 4, 5, 6, 11, 12]):\n",
    "                    line_color = COLORS['shoulder_hip']\n",
    "                elif (start == KEYPOINTS['left_shoulder'] and end == KEYPOINTS['right_shoulder']) or \\\n",
    "                        (start == KEYPOINTS['right_shoulder'] and end == KEYPOINTS['left_shoulder']):\n",
    "                    line_color = COLORS['shoulder_hip']\n",
    "                elif (start == KEYPOINTS['left_hip'] and end == KEYPOINTS['right_hip']) or \\\n",
    "                        (start == KEYPOINTS['right_hip'] and end == KEYPOINTS['left_hip']):\n",
    "                    line_color = COLORS['shoulder_hip']\n",
    "                else:\n",
    "                    line_color = (255, 255, 255)\n",
    "\n",
    "                cv2.line(image, (int(keypoints[start][0]), int(keypoints[start][1])),\n",
    "                         (int(keypoints[end][0]), int(keypoints[end][1])), line_color, line_size)\n",
    "\n",
    "        for i in range(len(keypoints)):\n",
    "            if keypoints[i][0] >= 0 and keypoints[i][1] >= 0:\n",
    "                if i in [0, 1, 2, 3, 4]:\n",
    "                    color = COLORS['face']\n",
    "                elif i in [5, 7, 9, 11, 13, 15]:\n",
    "                    color = COLORS['left']\n",
    "                elif i in [6, 8, 10, 12, 14, 16]:\n",
    "                    color = COLORS['right']\n",
    "                else:\n",
    "                    color = (255, 255, 255)\n",
    "\n",
    "                cv2.circle(image, (int(keypoints[i][0]), int(keypoints[i][1])), point_size, color, -1)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Error opening video file: {video_path}\")\n",
    "    return cap\n",
    "\n",
    "def load_keypoints(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return preprocess_dataframe(df)\n",
    "\n",
    "\n",
    "def plot_keypoints_on_frame(frame, keypoints, frame_number):\n",
    "    keypoints_all = []\n",
    "    for _, row in keypoints[keypoints['frame'] == frame_number].iterrows():\n",
    "        keypoints_object = []\n",
    "        for i in range(17):\n",
    "            x = int(row[f'keypoint_{i + 1:02d}_x'])\n",
    "            y = int(row[f'keypoint_{i + 1:02d}_y'])\n",
    "            keypoints_object.append((x, y))\n",
    "        keypoints_all.append(keypoints_object)\n",
    "    frame = visualize_coco_keypoints(frame, keypoints_all)\n",
    "    return frame\n",
    "\n",
    "\n",
    "def save_video(frames, output_path, fps, frame_size):\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, frame_size)\n",
    "    for frame in frames:\n",
    "        out.write(frame)\n",
    "    out.release()\n",
    "\n",
    "\n",
    "def filter_object_ids(df, min_frames=100):\n",
    "    \"\"\"\n",
    "    Drop all object_id with less than min_frames frames.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing the data.\n",
    "    min_frames (int): Minimum number of frames an object_id must have to be retained.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Filtered DataFrame.\n",
    "    \"\"\"\n",
    "    return df[df['object_id'].map(df['object_id'].value_counts()) > min_frames]\n",
    "\n",
    "def smooth_keypoints(df_cam14_filtered, window_size=5):\n",
    "    df_cam14_smooth = df_cam14_filtered.copy()\n",
    "    for object_id in df_cam14_filtered['object_id'].unique():\n",
    "        df_object = df_cam14_filtered[df_cam14_filtered['object_id'] == object_id]\n",
    "        for i in range(window_size, len(df_object) - window_size):\n",
    "            for j in range(17):\n",
    "                df_cam14_smooth.loc[df_object.index[i], f'keypoint_{j+1:02d}_x'] = df_object[f'keypoint_{j+1:02d}_x'].iloc[i-5:i+5].mean()\n",
    "                df_cam14_smooth.loc[df_object.index[i], f'keypoint_{j+1:02d}_y'] = df_object[f'keypoint_{j+1:02d}_y'].iloc[i-5:i+5].mean()\n",
    "    return df_cam14_smooth\n",
    "\n",
    "def preprocess_dataframe(df):\n",
    "    df['keypoints_array'] = df['keypoints'].apply(convert_string_to_array)\n",
    "    df = pd.concat(df.apply(expand_keypoints, axis=1).reset_index(drop=True).tolist(), ignore_index=True)\n",
    "    df.drop(['keypoints', 'bbox'], axis=1, inplace=True)\n",
    "    df.rename(columns={'keypoints_array': 'keypoints'}, inplace=True)\n",
    "    df = extract_keypoints(df)\n",
    "    df[['bbox_keypoint_x','bbox_keypoint_y','bbox_keypoint_w','bbox_keypoint_h']] = df.apply(get_bounding_box_from_keypoints, axis=1)\n",
    "    df = assign_object_ids(df)\n",
    "    df = filter_object_ids(df, min_frames=100)\n",
    "    df_smooth = smooth_keypoints(df)\n",
    "    return df_smooth\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_video(video_path, keypoints, output_path):\n",
    "    cap = load_video(video_path)\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, frame_size)\n",
    "\n",
    "    frame_number = 0\n",
    "    with tqdm(total=total_frames, desc=\"Processing frames\") as pbar:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = plot_keypoints_on_frame(frame, keypoints, frame_number)\n",
    "            out.write(frame)\n",
    "            frame_number += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(\"Video saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(video_path, csv_path, output_video_path):\n",
    "\n",
    "    df_keypoints = load_keypoints(csv_path)\n",
    "    process_video(video_path, df_keypoints, output_video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/gs/code/Challenge-1-Performance-Metrics-in-Sports-Climbing/script\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"Current working directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['semifinals_lead_women_and_men_cam14_03_pose_estimation_data.csv',\n",
       " 'semifinals_lead_women_and_men_cam14_pose_estimation_data.csv',\n",
       " 'semifinals_last_athlete_cam14_pose_estimation_data.csv',\n",
       " 'semifinals_lead_women_and_men_cam14_01_pose_estimation_data.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_folder = \"../keypoints\"\n",
    "os.listdir(csv_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 58343/58343 [1:02:38<00:00, 15.52it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 66841/66841 [49:04<00:00, 22.70it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 9031/9031 [07:17<00:00, 20.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    csv_folder = '../keypoints'\n",
    "    video_folder = '../data/videos'\n",
    "    video_output_folder = '../output/smoothing'\n",
    "    for filename in os.listdir(csv_folder):\n",
    "        if filename.endswith('.csv'):\n",
    "            video_name = filename.split('_pose_estimation_data.csv')[0]\n",
    "            csv_path = os.path.join(csv_folder, filename)\n",
    "            video_path = os.path.join(video_folder, video_name + '.avi')\n",
    "            output_video_path = os.path.join(video_output_folder, video_name + '_smoothed.mp4')\n",
    "            if not os.path.exists(output_video_path):\n",
    "                main(video_path, csv_path, output_video_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(video_path, csv_path, output_video_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climbing_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
